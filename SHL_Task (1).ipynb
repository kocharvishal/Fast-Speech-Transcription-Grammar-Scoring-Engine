{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 97919,
          "databundleVersionId": 11694977,
          "sourceType": "competition"
        },
        {
          "sourceId": 11302569,
          "sourceType": "datasetVersion",
          "datasetId": 7068492
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "JFqDe_enuC6C"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "shl_intern_hiring_assessment_path = kagglehub.competition_download('shl-intern-hiring-assessment')\n",
        "vishalkochar_shl_transcripts_path = kagglehub.dataset_download('vishalkochar/shl-transcripts')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "tnX3NXeEuC6E"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U openai-whisper"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T00:08:31.727355Z",
          "iopub.execute_input": "2025-04-07T00:08:31.727649Z",
          "iopub.status.idle": "2025-04-07T00:08:35.193327Z",
          "shell.execute_reply.started": "2025-04-07T00:08:31.72762Z",
          "shell.execute_reply": "2025-04-07T00:08:35.192423Z"
        },
        "id": "DqexLpknuC6E",
        "outputId": "378f5612-ac22-4c3c-9348-fde6ac384c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20240930)\nRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.67.1)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.9.0)\nRequirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (3.2.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2.4.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->openai-whisper) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T00:08:35.194355Z",
          "iopub.execute_input": "2025-04-07T00:08:35.194596Z",
          "iopub.status.idle": "2025-04-07T00:08:35.198708Z",
          "shell.execute_reply.started": "2025-04-07T00:08:35.194576Z",
          "shell.execute_reply": "2025-04-07T00:08:35.197788Z"
        },
        "id": "8ekZRrdpuC6F"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from multiprocessing import Pool\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T00:08:38.685764Z",
          "iopub.execute_input": "2025-04-07T00:08:38.686122Z",
          "iopub.status.idle": "2025-04-07T00:08:40.824255Z",
          "shell.execute_reply.started": "2025-04-07T00:08:38.686094Z",
          "shell.execute_reply": "2025-04-07T00:08:40.823541Z"
        },
        "id": "-WQTdR_NuC6F"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# === CONFIG ===\n",
        "NUM_BATCHES = 20\n",
        "available_devices = [\"cuda:0\", \"cuda:1\"]\n",
        "audio_folder = \"/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train\"\n",
        "output_dir = \".\"  # or any desired path for saving CSVs\n",
        "\n",
        "# List audio files\n",
        "audio_files = sorted([f for f in os.listdir(audio_folder) if f.endswith(\".wav\")])\n",
        "total_files = len(audio_files)\n",
        "\n",
        "# Split into 20 batches\n",
        "def chunkify(lst, n):\n",
        "    k, m = divmod(len(lst), n)\n",
        "    return [lst[i*k + min(i, m):(i+1)*k + min(i+1, m)] for i in range(n)]\n",
        "\n",
        "batches = chunkify(audio_files, NUM_BATCHES)\n",
        "\n",
        "# Transcription function\n",
        "def transcribe_file(args):\n",
        "    file_name, device = args\n",
        "    audio_path = os.path.join(audio_folder, file_name)\n",
        "\n",
        "    model = whisper.load_model(\"medium\").to(device)\n",
        "\n",
        "    result = model.transcribe(\n",
        "        audio_path,\n",
        "        fp16=True,\n",
        "        task=\"transcribe\",\n",
        "        language=\"en\",\n",
        "        condition_on_previous_text=False,\n",
        "        initial_prompt=None,\n",
        "        temperature=0.0,\n",
        "        no_speech_threshold=0.0,\n",
        "        logprob_threshold=-1.0,\n",
        "        compression_ratio_threshold=10.0\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"filename\": file_name,\n",
        "        \"transcription\": result[\"text\"]\n",
        "    }\n",
        "\n",
        "# Process all batches\n",
        "all_transcriptions = []\n",
        "\n",
        "for batch_idx, batch_files in enumerate(batches, 1):\n",
        "    print(f\"\\n Processing batch {batch_idx}/{NUM_BATCHES} with {len(batch_files)} files...\")\n",
        "\n",
        "    args_list = [\n",
        "        (file, available_devices[i % len(available_devices)])\n",
        "        for i, file in enumerate(batch_files)\n",
        "    ]\n",
        "\n",
        "    with Pool(processes=len(available_devices)) as pool:\n",
        "        batch_transcriptions = list(tqdm(pool.imap(transcribe_file, args_list), total=len(args_list)))\n",
        "\n",
        "    # Save batch results\n",
        "    df_batch = pd.DataFrame(batch_transcriptions)\n",
        "    batch_csv_path = os.path.join(output_dir, f\"transcriptions_batch_{batch_idx}.csv\")\n",
        "    df_batch.to_csv(batch_csv_path, index=False)\n",
        "    print(f\"Saved batch {batch_idx} to {batch_csv_path}\")\n",
        "\n",
        "    # Append to all results and save cumulative CSV\n",
        "    all_transcriptions.extend(batch_transcriptions)\n",
        "    df_all = pd.DataFrame(all_transcriptions)\n",
        "    all_csv_path = os.path.join(output_dir, f\"transcriptions_up_to_batch_{batch_idx}.csv\")\n",
        "    df_all.to_csv(all_csv_path, index=False)\n",
        "    print(f\"Saved cumulative transcription → {all_csv_path}\")\n",
        "\n",
        "print(\"\\n All batches completed successfully!\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "kQmRZO3ZuC6G"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# === CONFIG ===\n",
        "NUM_BATCHES = 10\n",
        "available_devices = [\"cuda:0\", \"cuda:1\"]\n",
        "audio_folder = \"/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test\"  # <-- Changed folder\n",
        "output_dir = \".\"  # where to save the results\n",
        "# ==============\n",
        "\n",
        "# List audio files\n",
        "audio_files = sorted([f for f in os.listdir(audio_folder) if f.endswith(\".wav\")])\n",
        "total_files = len(audio_files)\n",
        "\n",
        "# Split into 10 batches\n",
        "def chunkify(lst, n):\n",
        "    k, m = divmod(len(lst), n)\n",
        "    return [lst[i*k + min(i, m):(i+1)*k + min(i+1, m)] for i in range(n)]\n",
        "\n",
        "batches = chunkify(audio_files, NUM_BATCHES)\n",
        "\n",
        "# Transcription function\n",
        "def transcribe_file(args):\n",
        "    file_name, device = args\n",
        "    audio_path = os.path.join(audio_folder, file_name)\n",
        "\n",
        "    model = whisper.load_model(\"medium\").to(device)\n",
        "\n",
        "    result = model.transcribe(\n",
        "        audio_path,\n",
        "        fp16=True,\n",
        "        task=\"transcribe\",\n",
        "        language=\"en\",\n",
        "        condition_on_previous_text=False,\n",
        "        initial_prompt=None,\n",
        "        temperature=0.0,\n",
        "        no_speech_threshold=0.0,\n",
        "        logprob_threshold=-1.0,\n",
        "        compression_ratio_threshold=10.0\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"filename\": file_name,\n",
        "        \"transcription\": result[\"text\"]\n",
        "    }\n",
        "\n",
        "# Process all batches\n",
        "all_transcriptions = []\n",
        "\n",
        "for batch_idx, batch_files in enumerate(batches, 1):\n",
        "    print(f\"\\n Processing TEST batch {batch_idx}/{NUM_BATCHES} with {len(batch_files)} files...\")\n",
        "\n",
        "    args_list = [\n",
        "        (file, available_devices[i % len(available_devices)])\n",
        "        for i, file in enumerate(batch_files)\n",
        "    ]\n",
        "\n",
        "    with Pool(processes=len(available_devices)) as pool:\n",
        "        batch_transcriptions = list(tqdm(pool.imap(transcribe_file, args_list), total=len(args_list)))\n",
        "\n",
        "    # Save batch results\n",
        "    df_batch = pd.DataFrame(batch_transcriptions)\n",
        "    batch_csv_path = os.path.join(output_dir, f\"transcriptions_test_batch_{batch_idx}.csv\")\n",
        "    df_batch.to_csv(batch_csv_path, index=False)\n",
        "    print(f\"Saved batch {batch_idx} to {batch_csv_path}\")\n",
        "\n",
        "    # Append to all results and save cumulative CSV\n",
        "    all_transcriptions.extend(batch_transcriptions)\n",
        "    df_all = pd.DataFrame(all_transcriptions)\n",
        "    all_csv_path = os.path.join(output_dir, f\"transcriptions_test_up_to_batch_{batch_idx}.csv\")\n",
        "    df_all.to_csv(all_csv_path, index=False)\n",
        "    print(f\"Saved cumulative transcription → {all_csv_path}\")\n",
        "\n",
        "print(\"\\n All TEST batches completed successfully!\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "6D8u-mg4uC6G"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"/kaggle/input/shl-intern-hiring-assessment/dataset/train.csv\")\n",
        "df_train.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T00:08:47.496867Z",
          "iopub.execute_input": "2025-04-07T00:08:47.497444Z",
          "iopub.status.idle": "2025-04-07T00:08:47.512735Z",
          "shell.execute_reply.started": "2025-04-07T00:08:47.497409Z",
          "shell.execute_reply": "2025-04-07T00:08:47.511838Z"
        },
        "id": "BkTbaE3HuC6H",
        "outputId": "074884df-4614-4955-a2d1-e8697493ddf4"
      },
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         filename  label\n0  audio_1261.wav    1.0\n1   audio_942.wav    1.5\n2  audio_1110.wav    1.5\n3  audio_1024.wav    1.5\n4   audio_538.wav    2.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_1261.wav</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_942.wav</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_1110.wav</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_1024.wav</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_538.wav</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"/kaggle/input/shl-intern-hiring-assessment/dataset/test.csv\")\n",
        "df_test.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T00:08:49.004945Z",
          "iopub.execute_input": "2025-04-07T00:08:49.005295Z",
          "iopub.status.idle": "2025-04-07T00:08:49.014463Z",
          "shell.execute_reply.started": "2025-04-07T00:08:49.005265Z",
          "shell.execute_reply": "2025-04-07T00:08:49.013757Z"
        },
        "id": "XzBg3sXTuC6H",
        "outputId": "51fc5142-65b7-45a7-f819-767e3e4b7228"
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         filename\n0   audio_706.wav\n1   audio_800.wav\n2    audio_68.wav\n3  audio_1267.wav\n4   audio_683.wav",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_706.wav</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_800.wav</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_68.wav</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_1267.wav</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_683.wav</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# — CONFIG —\n",
        "# Paths to your original target CSVs\n",
        "TRAIN_META = \"/kaggle/input/shl-intern-hiring-assessment/dataset/train.csv\"\n",
        "TEST_META  = \"/kaggle/input/shl-intern-hiring-assessment/dataset/test.csv\"\n",
        "\n",
        "# Paths to your cumulative transcription outputs\n",
        "TRAIN_TRANS_CUM = \"/kaggle/input/shl-transcripts/transcriptions_up_to_batch_20.csv\"        # from your train script\n",
        "TEST_TRANS_CUM  = \"/kaggle/input/shl-transcripts/transcriptions_test_up_to_batch_10.csv\"   # from your test script\n",
        "\n",
        "# Output filenames\n",
        "TRAIN_READY = \"train_ready.csv\"\n",
        "TEST_READY  = \"test_ready.csv\"\n",
        "# — end CONFIG —\n",
        "\n",
        "# 1) Load metadata\n",
        "df_meta_train = pd.read_csv(TRAIN_META)   # columns: [filename, label]\n",
        "df_meta_test  = pd.read_csv(TEST_META)    # columns: [filename]\n",
        "\n",
        "# 2) Load transcriptions\n",
        "df_trans_train = pd.read_csv(TRAIN_TRANS_CUM)  # [filename, transcription]\n",
        "df_trans_test  = pd.read_csv(TEST_TRANS_CUM)   # [filename, transcription]\n",
        "\n",
        "# 3) Merge train\n",
        "df_train_ready = (\n",
        "    df_meta_train\n",
        "    .merge(df_trans_train, on=\"filename\", how=\"left\")\n",
        "    .loc[:, [\"filename\", \"transcription\", \"label\"]]\n",
        ")\n",
        "df_train_ready.to_csv(TRAIN_READY, index=False)\n",
        "print(f\"Saved train‑ready data → {TRAIN_READY}\")\n",
        "\n",
        "# 4) Merge test\n",
        "df_test_ready = (\n",
        "    df_meta_test\n",
        "    .merge(df_trans_test, on=\"filename\", how=\"left\")\n",
        "    .loc[:, [\"filename\", \"transcription\"]]\n",
        ")\n",
        "df_test_ready.to_csv(TEST_READY, index=False)\n",
        "print(f\"Saved test‑ready data → {TEST_READY}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T00:08:50.789596Z",
          "iopub.execute_input": "2025-04-07T00:08:50.789967Z",
          "iopub.status.idle": "2025-04-07T00:08:50.834172Z",
          "shell.execute_reply.started": "2025-04-07T00:08:50.78992Z",
          "shell.execute_reply": "2025-04-07T00:08:50.833418Z"
        },
        "id": "h8_Yv3GWuC6I",
        "outputId": "93717292-0fe9-4e38-d0c3-3990e60e147e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "✅ Saved train‑ready data → train_ready.csv\n✅ Saved test‑ready data → test_ready.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_ready.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T00:08:53.878184Z",
          "iopub.execute_input": "2025-04-07T00:08:53.878524Z",
          "iopub.status.idle": "2025-04-07T00:08:53.88757Z",
          "shell.execute_reply.started": "2025-04-07T00:08:53.878496Z",
          "shell.execute_reply": "2025-04-07T00:08:53.886463Z"
        },
        "id": "jdtpDfvzuC6I",
        "outputId": "25a24439-9d82-47e2-d435-f9b71e1560f7"
      },
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         filename                                      transcription  label\n0  audio_1261.wav   My favorite hobby is cultivation of plants su...    1.0\n1   audio_942.wav   The playground looks like very clear and neat...    1.5\n2  audio_1110.wav   My goal is to become an electrical employee. ...    1.5\n3  audio_1024.wav   My favorite place is in Andhra Pradesh. It is...    1.5\n4   audio_538.wav   my favorite places my favorite places my expe...    2.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>transcription</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_1261.wav</td>\n      <td>My favorite hobby is cultivation of plants su...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_942.wav</td>\n      <td>The playground looks like very clear and neat...</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_1110.wav</td>\n      <td>My goal is to become an electrical employee. ...</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_1024.wav</td>\n      <td>My favorite place is in Andhra Pradesh. It is...</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_538.wav</td>\n      <td>my favorite places my favorite places my expe...</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T00:08:55.459652Z",
          "iopub.execute_input": "2025-04-07T00:08:55.459985Z",
          "iopub.status.idle": "2025-04-07T00:09:00.291289Z",
          "shell.execute_reply.started": "2025-04-07T00:08:55.459959Z",
          "shell.execute_reply": "2025-04-07T00:09:00.290572Z"
        },
        "id": "ySQ0heOMuC6I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "MODEL_NAME = 'roberta-large'\n",
        "NUM_LABELS = 1  # Regression task\n",
        "MAX_LENGTH = 512\n",
        "CHUNK_SIZE = 150  # Each chunk will have approximately 150 characters\n",
        "OVERLAP = 50     # Overlap between chunks\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 2e-6\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = RobertaForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS).to(DEVICE)\n",
        "\n",
        "# Custom dataset class\n",
        "class GrammarDataset(Dataset):\n",
        "    def __init__(self, texts, scores, tokenizer, max_length, chunk_size, overlap):\n",
        "        self.texts = [str(t) if not pd.isna(t) else \"\" for t in texts]\n",
        "        self.scores = scores\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.chunk_size = chunk_size\n",
        "        self.overlap = overlap\n",
        "        self.data = self._prepare_data()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        data = []\n",
        "        for text, score in zip(self.texts, self.scores):\n",
        "            chunks = self.split_into_chunks(text)\n",
        "            for chunk in chunks:\n",
        "                data.append((chunk, score))\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        chunk, score = self.data[idx]\n",
        "        inputs = self.tokenizer(chunk, padding='max_length', truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].squeeze(0),\n",
        "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
        "            'score': torch.tensor(score, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "    def split_into_chunks(self, text):\n",
        "        words = text.split()\n",
        "        chunks = []\n",
        "        start = 0\n",
        "        while start < len(words):\n",
        "            end = min(start + self.chunk_size, len(words))\n",
        "            chunk = ' '.join(words[start:end])\n",
        "            chunks.append(chunk)\n",
        "            if end == len(words):\n",
        "                break\n",
        "            start += self.chunk_size - self.overlap\n",
        "        return chunks"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T00:09:00.29258Z",
          "iopub.execute_input": "2025-04-07T00:09:00.293287Z",
          "iopub.status.idle": "2025-04-07T00:09:01.59598Z",
          "shell.execute_reply.started": "2025-04-07T00:09:00.293249Z",
          "shell.execute_reply": "2025-04-07T00:09:01.595259Z"
        },
        "id": "d32mCDGGuC6J",
        "outputId": "2a094487-1410-4572-b529-1edf14516bd6"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path, with_labels=True):\n",
        "    df = pd.read_csv(file_path)\n",
        "    texts = df['transcription'].tolist()\n",
        "    if with_labels:\n",
        "        scores = df['label'].tolist()\n",
        "        return texts, scores\n",
        "    else:\n",
        "        filenames = df['filename'].tolist()\n",
        "        return filenames, texts\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, val_loader, epochs, learning_rate, device):\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        train_preds = []\n",
        "        train_scores = []\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            scores = batch['score'].to(device)\n",
        "            if scores.dim() == 0:\n",
        "                scores = scores.unsqueeze(0)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits.squeeze()\n",
        "            if logits.dim() == 0:\n",
        "                logits = logits.unsqueeze(0)\n",
        "            loss = loss_fn(logits, scores)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            train_preds.extend(logits.detach().cpu().numpy())\n",
        "            train_scores.extend(scores.cpu().numpy())\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        train_mse = mean_squared_error(train_scores, train_preds)\n",
        "        train_acc = accuracy_score(\n",
        "            [round(p) for p in train_preds],\n",
        "            [round(s) for s in train_scores]\n",
        "        )\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Train MSE: {train_mse:.4f} | Train Accuracy: {train_acc:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_scores = []\n",
        "        val_preds = []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                scores = batch['score'].to(device)\n",
        "\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits.squeeze()\n",
        "                val_preds.extend(logits.cpu().numpy())\n",
        "                val_scores.extend(scores.cpu().numpy())\n",
        "                val_acc = accuracy_score(\n",
        "                    [round(p) for p in val_preds],\n",
        "                    [round(s) for s in val_scores]\n",
        "                )\n",
        "\n",
        "        val_mse = mean_squared_error(val_scores, val_preds)\n",
        "        print(f\"Validation MSE: {val_mse:.4f} | Validation Accuracy: {val_acc:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T00:09:04.342425Z",
          "iopub.execute_input": "2025-04-07T00:09:04.342771Z",
          "iopub.status.idle": "2025-04-07T00:09:04.352761Z",
          "shell.execute_reply.started": "2025-04-07T00:09:04.342739Z",
          "shell.execute_reply": "2025-04-07T00:09:04.35191Z"
        },
        "id": "dz8mT9FCuC6J"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load training data\n",
        "train_texts, train_scores = load_data('train_ready.csv')\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_texts, val_texts, train_scores, val_scores = train_test_split(train_texts, train_scores, test_size=0.1, random_state=42)\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = GrammarDataset(train_texts, train_scores, tokenizer, MAX_LENGTH, CHUNK_SIZE, OVERLAP)\n",
        "val_dataset = GrammarDataset(val_texts, val_scores, tokenizer, MAX_LENGTH, CHUNK_SIZE, OVERLAP)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, val_loader, EPOCHS, LEARNING_RATE, DEVICE)\n",
        "\n",
        "    # Save the trained model\n",
        "model.save_pretrained('grammar_score_model')\n",
        "tokenizer.save_pretrained('grammar_score_model')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T00:09:07.407065Z",
          "iopub.execute_input": "2025-04-07T00:09:07.407381Z",
          "iopub.status.idle": "2025-04-07T00:21:13.097034Z",
          "shell.execute_reply.started": "2025-04-07T00:09:07.407357Z",
          "shell.execute_reply": "2025-04-07T00:21:13.096088Z"
        },
        "id": "BrCxTy17uC6J",
        "outputId": "521577d7-0cbd-4b8e-c701-1d2abb7182a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5 | Train Loss: 4.0392 | Train MSE: 4.0819 | Train Accuracy: 0.1940\nValidation MSE: 1.7786 | Validation Accuracy: 0.2500\nEpoch 2/5 | Train Loss: 1.8365 | Train MSE: 1.8583 | Train Accuracy: 0.3048\nValidation MSE: 1.4395 | Validation Accuracy: 0.4423\nEpoch 3/5 | Train Loss: 1.4699 | Train MSE: 1.4880 | Train Accuracy: 0.3464\nValidation MSE: 1.4481 | Validation Accuracy: 0.5000\nEpoch 4/5 | Train Loss: 1.1961 | Train MSE: 1.1985 | Train Accuracy: 0.4018\nValidation MSE: 1.2458 | Validation Accuracy: 0.4423\nEpoch 5/5 | Train Loss: 0.8889 | Train MSE: 0.8986 | Train Accuracy: 0.4596\nValidation MSE: 1.2350 | Validation Accuracy: 0.4615\n",
          "output_type": "stream"
        },
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "('grammar_score_model/tokenizer_config.json',\n 'grammar_score_model/special_tokens_map.json',\n 'grammar_score_model/vocab.json',\n 'grammar_score_model/merges.txt',\n 'grammar_score_model/added_tokens.json')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data without labels\n",
        "test_df = pd.read_csv('test_ready.csv')\n",
        "test_filenames = test_df['filename'].tolist()\n",
        "test_texts = test_df['transcription'].tolist()\n",
        "\n",
        "# Dummy scores (not used)\n",
        "dummy_scores = [0.0] * len(test_texts)\n",
        "\n",
        "# Create test dataset and loader\n",
        "test_dataset = GrammarDataset(test_texts, dummy_scores, tokenizer, MAX_LENGTH, CHUNK_SIZE, OVERLAP)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Predict and collect per-chunk scores\n",
        "model.eval()\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(DEVICE)\n",
        "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits.squeeze()\n",
        "\n",
        "        if logits.dim() == 0:\n",
        "            all_preds.append(logits.item())\n",
        "        else:\n",
        "            all_preds.extend(logits.cpu().numpy())\n",
        "\n",
        "# Group predictions by original test texts (accounting for chunking)\n",
        "chunk_counts = []\n",
        "for text in test_texts:\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        chunk_counts.append(1)  # handle empty or bad text with 1 dummy chunk\n",
        "    else:\n",
        "        temp_dataset = GrammarDataset([text], [0.0], tokenizer, MAX_LENGTH, CHUNK_SIZE, OVERLAP)\n",
        "        chunk_counts.append(len(temp_dataset))\n",
        "\n",
        "\n",
        "final_preds = []\n",
        "i = 0\n",
        "for count in chunk_counts:\n",
        "    preds = all_preds[i:i + count]\n",
        "    avg_pred = sum(preds) / len(preds)\n",
        "    final_preds.append(min(5, max(1, round(avg_pred))))  # Clamp between 1 and 5\n",
        "    i += count\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission_df = pd.DataFrame({'filename': test_filenames, 'label': final_preds})\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"Submission file saved as 'submission.csv'\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T00:45:17.630381Z",
          "iopub.execute_input": "2025-04-07T00:45:17.630717Z",
          "iopub.status.idle": "2025-04-07T00:45:42.012916Z",
          "shell.execute_reply.started": "2025-04-07T00:45:17.630692Z",
          "shell.execute_reply": "2025-04-07T00:45:42.012054Z"
        },
        "id": "nvdpQLr2uC6J",
        "outputId": "68e33ddb-3ad8-4101-c1c3-ef30ce498e19"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "✅ Submission file saved as 'submission.csv'\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T00:45:42.014071Z",
          "iopub.execute_input": "2025-04-07T00:45:42.014369Z",
          "iopub.status.idle": "2025-04-07T00:45:42.023285Z",
          "shell.execute_reply.started": "2025-04-07T00:45:42.014338Z",
          "shell.execute_reply": "2025-04-07T00:45:42.022345Z"
        },
        "id": "siJNa4qSuC6J",
        "outputId": "02d2642f-b116-42ad-cc0d-a89da527dbd8"
      },
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "           filename  label\n0     audio_706.wav      3\n1     audio_800.wav      3\n2      audio_68.wav      4\n3    audio_1267.wav      3\n4     audio_683.wav      3\n..              ...    ...\n190   audio_135.wav      4\n191   audio_512.wav      5\n192   audio_529.wav      5\n193   audio_762.wav      5\n194   audio_379.wav      5\n\n[195 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_706.wav</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_800.wav</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_68.wav</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_1267.wav</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_683.wav</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>audio_135.wav</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>audio_512.wav</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>audio_529.wav</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>audio_762.wav</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>194</th>\n      <td>audio_379.wav</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>195 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "sJcb0UdCuC6J"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "TebEwFu0uC6J"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}